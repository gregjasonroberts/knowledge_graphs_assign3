Part 1:

Structured querying in knowledge graphs relies heavily on SPARQL, the W3C‑standardized RDF query language designed to express graph patterns as sets of triple templates. Variables prefixed with “?” bind to subjects, predicates, or objects, and shared variables across multiple patterns naturally result in join operations. SPARQL 1.1 extends basic pattern matching with SQL‑style features such as aggregates, subqueries, optional patterns, and negation, enabling complex queries (e.g., grouping, ordering) that go beyond simple triple matching. Its formal semantics and bottom‑up evaluation model allow systems to leverage decades of relational query optimization research, even though RDF data often resists straightforward tabular representation :contentReference[oaicite:0]{index=0}.

Relational RDF stores implement three main physical layouts—triple‑table, property‑table, and horizontal (vertical partitioning)—each trading off between schema simplicity and query performance. In a triple‑table store, every RDF triple is stored in one large table (subject, predicate, object) with extensive indexing; while this generality simplifies ingestion, complex queries incur many self‑joins and can suffer severe I/O bottlenecks :contentReference[oaicite:1]{index=1}. Property‑table stores co‑locate a subject’s common properties in wide tables, reducing joins for multi‑predicate lookups but requiring careful schema design or adaptive clustering to avoid sparse columns :contentReference[oaicite:2]{index=2}. Horizontal stores split data into one two‑column table per predicate, sorted by subject; this vertical partitioning simplifies table creation and reduces union clauses yet demands merge‑joins across many narrow tables :contentReference[oaicite:3]{index=3}.

When RDF’s strict schema or URI requirements become burdensome, NoSQL wide‑column stores offer an alternative for semi‑structured graph data. Apache Cassandra implements a distributed, partitioned wide‑column model with tunable consistency and fault tolerance, excelling at horizontal scaling and high‑throughput writes and reads across commodity servers :contentReference[oaicite:4]{index=4}. Similarly, Apache HBase—modeled after Google’s Bigtable—provides versioned, sparse tables on HDFS capable of hosting billions of rows and millions of columns, offering random real‑time access and seamless integration with the Hadoop ecosystem :contentReference[oaicite:5]{index=5}.

Beyond RDF, property‑graph databases and hypergraphs extend expressivity and developer ergonomics for graph querying. Neo4j’s property‑graph model attaches arbitrary key–value properties to nodes and relationships and exposes them via the Cypher DSL, a declarative, ASCII‑art‑style language (`MATCH`, `WHERE`, `RETURN`) that abstracts away explicit join syntax and emphasizes pattern matching :contentReference[oaicite:6]{index=6}. Hypergraph databases generalize edges to hyperedges that can connect any number of vertices—often represented as nested “hypernodes”—making it easier to model higher‑order relations without decomposing them into multiple binary triples :contentReference[oaicite:7]{index=7}.
::contentReference[oaicite:8]{index=8}
